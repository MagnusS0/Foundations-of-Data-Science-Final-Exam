{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os \n",
    "import numpy as np \n",
    "import string \n",
    "import pandas as pd \n",
    "from numpy.linalg import norm\n",
    "import re \n",
    "\n",
    "\n",
    "class StringSimilarity: \n",
    "    \n",
    "    \n",
    "    def __init__(self): \n",
    "        \n",
    "        #list with all documents \n",
    "        self.document_pool = {}\n",
    "        \n",
    "        self.vector_pool = {}\n",
    "        \n",
    "        #dictionary with all words -> without punctation and special characters \n",
    "        self.dictionary = set()\n",
    "        \n",
    "        self.stopwords = [\n",
    "            \n",
    "        \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n",
    "        \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n",
    "        \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n",
    "        \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n",
    "        \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n",
    "        \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n",
    "        \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n",
    "        \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n",
    "        \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \n",
    "        \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \n",
    "        \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \n",
    "        \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\" \n",
    "        ]\n",
    "     \n",
    "    \n",
    "    def add_documents(self,name, document): \n",
    "        \n",
    "        processed_document = self.main_cleaning(document)\n",
    "        \n",
    "        if processed_document not in list(self.document_pool.keys()): \n",
    "            \n",
    "            self.document_pool[name] = processed_document\n",
    "            \n",
    "            self.dictionary.update(set(processed_document))\n",
    "            self.update_vectorpool() \n",
    "            \n",
    "        else: \n",
    "            raise ValueError(\"Text has already been added to pool\")\n",
    "    \n",
    "    def add_texts(self): \n",
    "        \n",
    "        pass \n",
    "    # methods to clean and prepare the text documents\n",
    "    \n",
    "    @staticmethod\n",
    "    def cleaning_text(text): \n",
    "        \n",
    "        text = text.strip()\n",
    "        text = re.sub(r'(?<=\\w)[_-]|[_-](?=\\w)', '', text)\n",
    "        text = re.sub(r'\\b(?:[a-zA-Z]\\.)+[a-zA-Z]?[,]*\\b', ' ', text)\n",
    "        text = re.sub(r\"\\W\", \" \", text)  #remove non words char\n",
    "        text = re.sub(r\"\\d\", \" \", text)  #remove digits char\n",
    "        text = re.sub(r\"[\\s]+\", \" \", text) # remove extra white space\n",
    "        text = text.lower() #lower char for matching\n",
    "        return text \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_text(path):\n",
    "     \n",
    "        with open(path, 'r') as file: #closed after reading \n",
    "            \n",
    "            file = StringSimilarity.string_to_list(file.read())\n",
    "        \n",
    "        return file\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_doc_list(curr_path): \n",
    "        \n",
    "        corpus_path = os.path.join(curr_path, 'Corpus')\n",
    "\n",
    "        objects = os.listdir(corpus_path)\n",
    "        \n",
    "        return objects \n",
    "\n",
    "    def create_corpus(self): \n",
    "        \n",
    "        path = os.getcwd()\n",
    "        text_files = StringSimilarity.create_doc_list(path)\n",
    "        \n",
    "        corpus_path = os.path.join(path, 'Corpus')\n",
    "        new_count = 0\n",
    "        \n",
    "        for i in text_files: \n",
    "            \n",
    "            if i.endswith('.txt'): \n",
    "                \n",
    "                if i not in self.document_pool.keys(): \n",
    "                    \n",
    "                    temp_text = StringSimilarity.load_text(os.path.join(corpus_path, i))\n",
    "                    temp_text = self.removing_stopwords(temp_text)\n",
    "\n",
    "                    self.dictionary.update(set(temp_text))\n",
    "                    self.document_pool[i] = list(set(temp_text))\n",
    "                    new_count+= 1 \n",
    "                    \n",
    "                else: \n",
    "                    continue\n",
    "            else: \n",
    "                continue \n",
    "        \n",
    "        self.update_vectorpool()  \n",
    "        \n",
    "        if new_count == 0: \n",
    "            \n",
    "            return \"no new documents in folder\"\n",
    "        else: \n",
    "            \n",
    "            return f\"where have been {str(new_count)} new documents in the folder\"\n",
    "            \n",
    "        return \"Corpus created\"\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def string_to_list(string1): \n",
    "        \n",
    "        clean_text = StringSimilarity.cleaning_text(string1)\n",
    "\n",
    "        \n",
    "        return clean_text.split()\n",
    "\n",
    "    # removing stopwords \n",
    "\n",
    "    def removing_stopwords(self, list_words): \n",
    "\n",
    "        text_without_stop = [word for word in list_words if word not in self.stopwords]\n",
    "        \n",
    "        return text_without_stop\n",
    "    \n",
    "    \n",
    "    def main_cleaning(self, text): \n",
    "        \n",
    "        text_list = StringSimilarity.string_to_list(text)\n",
    "        text_list = self.removing_stopwords(text_list)\n",
    "        \n",
    "        return text_list      \n",
    "    \n",
    "   \n",
    "\n",
    "    def create_vector(self, word_list): \n",
    "    \n",
    "        vector = [0] * len(self.dictionary)\n",
    "        \n",
    "\n",
    "        # maybe better performance if we delete word from dict temporally -> lenght of loop would be reducing by each run\n",
    "        for i, word in enumerate(self.dictionary): \n",
    "            \n",
    "            if word in word_list: \n",
    "                vector[i] = 1\n",
    "            else: \n",
    "                continue \n",
    "            \n",
    "        return vector \n",
    "    \n",
    "    \n",
    "    def update_vectorpool(self): \n",
    "        \n",
    "        for i in self.document_pool.keys(): \n",
    "            \n",
    "            self.vector_pool[i] = self.create_vector(self.document_pool[i])\n",
    "            \n",
    "        print(\"all vectors are updated\") \n",
    "\n",
    "    @staticmethod\n",
    "    def rank_vectors(dict1): \n",
    "        \n",
    "        return dict(sorted(dict1.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def dot_product_normal(self, new_doc): \n",
    "        \n",
    "        final_dict = {}\n",
    "        \n",
    "        clean_text = self.main_cleaning(new_doc)\n",
    "        \n",
    "        new_vector = self.create_vector(clean_text)\n",
    "        \n",
    "        for text in self.document_pool.keys(): \n",
    "\n",
    "            final_dict[text] = np.dot(new_vector, self.vector_pool[text])\n",
    "        \n",
    "        return StringSimilarity.rank_vectors(final_dict)\n",
    "    \n",
    "    \n",
    "\n",
    "    def cosine_Similarity(self, new_doc): \n",
    "        \n",
    "        cosine_values = {}\n",
    "        \n",
    "        clean_text = self.main_cleaning(new_doc)\n",
    "        \n",
    "        new_vector = self.create_vector(clean_text)\n",
    "        \n",
    "        for i in self.document_pool.keys(): \n",
    "            \n",
    "            temp_vector = self.vector_pool[i]\n",
    "            \n",
    "            if norm(new_vector)*norm(temp_vector) != 0: \n",
    "                \n",
    "                cosine = np.dot(new_vector,temp_vector)/(norm(new_vector)*norm(temp_vector))\n",
    "                \n",
    "                cosine_values[i] = cosine\n",
    "                \n",
    "            else: \n",
    "                cosine_values[i] = 'no matches'\n",
    "            \n",
    "        return StringSimilarity.rank_vectors(cosine_values)\n",
    "    \n",
    "    \n",
    "    def Euclidean_distance(self, new_doc): \n",
    "        \n",
    "        euclidean_values = {}\n",
    "        clean_text = self.main_cleaning(new_doc)\n",
    "        new_vector = self.create_vector(clean_text)\n",
    "        \n",
    "        for i in self.document_pool.keys(): \n",
    "            \n",
    "            temp_vector = self.vector_pool[i]\n",
    "            \n",
    "            dist = np.linalg.norm(np.array(temp_vector) - np.array(new_vector))\n",
    "            euclidean_values[i] = dist \n",
    "            \n",
    "        return StringSimilarity.rank_vectors(euclidean_values)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_dataframe(dict1, dict2, dict3): \n",
    "        \n",
    "        df = pd.DataFrame([dict1,dict2, dict3 ])\n",
    "        \n",
    "        df = df.T\n",
    "    \n",
    "        df.columns = [\"dot_product\", \"cosine\", \"Euclidean\"]\n",
    "        \n",
    "        return df \n",
    "    \n",
    "    def user_interaction(self): \n",
    "        \n",
    "            \n",
    "        q1 = input('Please Enter the text you want to compare and press Enter')\n",
    "        \n",
    "        result1 = self.dot_product_normal(q1)\n",
    "\n",
    "        result2 = self.cosine_Similarity(q1)\n",
    "\n",
    "        result3 = self.Euclidean_distance(q1)\n",
    "\n",
    "                    \n",
    "        return StringSimilarity.create_dataframe(result1, result2, result3)\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all vectors are updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'where have been 2 new documents in the folder'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_pool3 = StringSimilarity()\n",
    "document_pool3.create_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all vectors are updated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_string = \"If this is the case, they have the right to access their personal data held by the controller, thereby ensuring the transparency of the data processing. The controller should provide the data subject with a copy of all information about the data subject upon receipt of the request. The information should include the purpose of the data processing, the categories of personal data, the duration of storage, the recipients of the data, the rights to rectification, erasure or restriction of the data, the right to lodge a complaint, the source of the data if it was not collected from the data subject, and information on automated decision-making. (Trzaskowski and Gersvang Sørensen, 2022) Grindr has introduced two methods for applying Article 15. The first allows the user to download their data within the Grindr application and secondly the user can request the data with a form. The online form allows users to make personalized written requests about their data and request the deletion of their account and data\"\n",
    "document_pool3.add_documents(\"text1\", test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot_product</th>\n",
       "      <th>cosine</th>\n",
       "      <th>Euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text2.txt</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.392546</td>\n",
       "      <td>9.643651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example1.txt</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.332956</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.375244</td>\n",
       "      <td>7.874008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dot_product    cosine  Euclidean\n",
       "text2.txt            25.0  0.392546   9.643651\n",
       "example1.txt         21.0  0.332956   9.949874\n",
       "text1                18.0  0.375244   7.874008"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_pool3.user_interaction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
