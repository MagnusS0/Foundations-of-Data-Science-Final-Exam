{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!pip install numpy \n",
    "\n",
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from numpy.linalg import norm\n",
    "import re \n",
    "\n",
    "\n",
    "\n",
    "class StringSimilarity: \n",
    "    \n",
    "    \"\"\"\n",
    "    A class for computing string similarity using various metrics.\n",
    "    This class provides functionality to clean and process text documents,\n",
    "    calculate similarity scores, and manage a collection of text documents.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self): \n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the StringSimilarity class with empty structures for storing documents.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Dictionary to store the processed documents\n",
    "        self.document_pool = {}\n",
    "        \n",
    "        # Dictionary to store vector representations of the documents\n",
    "        self.vector_pool = {}\n",
    "        \n",
    "        # Set to store unique words across all documents\n",
    "        self.dictionary = set()\n",
    "        \n",
    "        \n",
    "        # list of stopwords for basic text filtering\n",
    "        self.stopwords = [\n",
    "            \n",
    "        \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n",
    "        \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \n",
    "        \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \n",
    "        \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \n",
    "        \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \n",
    "        \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \n",
    "        \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n",
    "        \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n",
    "        \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \n",
    "        \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \n",
    "        \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \n",
    "        \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\" \n",
    "        ]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_documents(self,name, document): \n",
    "        \n",
    "        \"\"\"\n",
    "        Manual adds a document to the document pool after processing it.\n",
    "\n",
    "        Args:\n",
    "            name (str): The name or identifier for the document.\n",
    "            document (str): The text of the document to be added.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If document or name is string\n",
    "            ValueError: If name or document is empty \n",
    "            ValueError: Processed document is empty. It might contain only stopwords or non-words\n",
    "            ValueError: If the processed document already exists in the document pool.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if not isinstance(name, str) or not isinstance(document, str):\n",
    "            \n",
    "            \n",
    "            raise TypeError(\"Both name and document must be strings.\")\n",
    "        \n",
    "        if not name:\n",
    "            raise ValueError(\"Document name is empty.\")\n",
    "    \n",
    "        if not document:\n",
    "            raise ValueError(\"Document content is empty.\")\n",
    "        \n",
    "        \n",
    "        processed_document = self.main_cleaning(document)\n",
    "        \n",
    "        if not processed_document:\n",
    "            raise ValueError(\"Processed document is empty. It might contain only stopwords or non-words.\")\n",
    "        \n",
    "        \n",
    "        # Check if the document is not already in the pool\n",
    "        if processed_document not in list(self.document_pool.keys()): \n",
    "            \n",
    "            self.document_pool[name] = processed_document\n",
    "            \n",
    "            if not bool(set(processed_document) & self.dictionary): \n",
    "            \n",
    "                self.dictionary.update(set(processed_document))\n",
    "                \n",
    "                # after a new document is added to pool, all vectors have to be updated because dictionary is longer. \n",
    "                self.update_vectorpool() \n",
    "            else: \n",
    "                self.vector_pool[name] = self.create_vector(processed_document)\n",
    "                \n",
    "                print(\"Text has been added to the pool but no new vocabularies were added.\")\n",
    "            \n",
    "        else: \n",
    "            raise ValueError(f\"The text {processed_document} has already been added to pool\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cleaning_text(text): \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Static method to clean a given text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be cleaned.\n",
    "\n",
    "        Returns:\n",
    "            str: The cleaned text.\n",
    "            \n",
    "        Raises: \n",
    "            TypeError: If the input text is not a string.\n",
    "            ValueError: If Input text is empty or only contains whitespace\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(text, str):\n",
    "            raise TypeError(\"Input text must be a string.\")\n",
    "        \n",
    "        if text.strip() == \"\":\n",
    "            \n",
    "            raise ValueError(\"Input text is empty or only contains whitespace.\")\n",
    "        \n",
    "        \n",
    "        text = text.strip() # removes whitespaces in the beginning and end\n",
    "        text = re.sub(r'\\b[_-]+|(?<=\\w)[_-]+|[_-]+(?=\\w)', '', text) # Removes hyphens or underscores that are surrounded by word characters.\n",
    "        text = re.sub(r'\\b(?:[a-zA-Z]\\.)+[a-zA-Z]?[,]*\\b', ' ', text) # Replaces abbreviations or initials and optional trailing commas with a space.\n",
    "        text = re.sub(r\"\\W\", \" \", text)  #remove non words char\n",
    "        text = re.sub(r\"\\d\", \" \", text)  #remove digits char\n",
    "        text = re.sub(r\"[\\s]+\", \" \", text) # remove extra white space\n",
    "        text = text.lower() #lower char for matching\n",
    "        \n",
    "        return text \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_text(path):\n",
    "        \n",
    "        \"\"\"\n",
    "        Static method to load text from a given file path.\n",
    "\n",
    "        Args:\n",
    "            path (str): The file path from which to load the text.\n",
    "\n",
    "        Returns:\n",
    "            list: The processed list of words from the file.\n",
    "        \n",
    "        Raises: \n",
    "            ValueError: If input is not a string\n",
    "            FileNotFoundError: If the path can not be found within the operating system \n",
    "        \"\"\"\n",
    "        if not isinstance(path, str): \n",
    "            \n",
    "            raise ValueError(\"The file path must be a string.\")\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"The file does not exist at the path: {path}\")\n",
    "        \n",
    "        \n",
    "        # add try ... except???\n",
    "        with open(path, 'r') as file: #Automatically closes the file after reading\n",
    "            \n",
    "            #file = StringSimilarity.string_to_list(file.read())\n",
    "            \n",
    "            file = file.read()\n",
    "        \n",
    "        return file\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_doc_list(curr_path): \n",
    "        \n",
    "        \"\"\"\n",
    "        Static method to create a list of document names in the 'Corpus' directory.\n",
    "\n",
    "        Args:\n",
    "            curr_path (str): The current working directory path.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of filenames found in the 'Corpus' subdirectory.\n",
    "            \n",
    "        Raises: \n",
    "            FileNotFoundError: If the path can not be found within the operating system \n",
    "        \"\"\"\n",
    "        \n",
    "        # Construct the path to the 'Corpus' directory which contains .txt files\n",
    "        corpus_path = os.path.join(curr_path, 'Corpus')\n",
    "        \n",
    "        if not os.path.exists(corpus_path):\n",
    "            raise FileNotFoundError(f\"The file does not exist at the path: {corpus_path}\")\n",
    "\n",
    "        # List all files in the 'Corpus' directory\n",
    "        objects = os.listdir(corpus_path)\n",
    "        \n",
    "        return objects \n",
    "\n",
    "    def create_corpus(self): \n",
    "        \n",
    "        \"\"\"\n",
    "        Method to create a corpus by processing and adding text files from the 'Corpus' directory.\n",
    "        Updates the document pool with new documents and their processed content.\n",
    "        \n",
    "        Returns:\n",
    "            str: A message indicating the outcome of the corpus creation\n",
    "        \n",
    "        Raises: \n",
    "            Exception: If an unexpected error occurs during file processing.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the current working directory\n",
    "        path = os.getcwd()\n",
    "        \n",
    "        # Retrieve the list of text files in the 'Corpus' directory\n",
    "        \n",
    "        try: \n",
    "            \n",
    "            text_files = StringSimilarity.create_doc_list(path)\n",
    "            \n",
    "        except Exception as e: \n",
    "            \n",
    "            raise Exception(f'Failed to create document list: {e}')\n",
    "        \n",
    "        # create path to Corpus folder \n",
    "        corpus_path = os.path.join(path, 'Corpus')\n",
    "        \n",
    "        # count number of documents\n",
    "        new_count = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in text_files: \n",
    "            \n",
    "            # Process only text files and avoid duplicates\n",
    "            if i.endswith('.txt'): \n",
    "                \n",
    "                # avoid duplicates in document pool\n",
    "                if i not in self.document_pool.keys(): \n",
    "                    \n",
    "                    \n",
    "                    try: \n",
    "                    # Load and process the text file\n",
    "                        temp_text = StringSimilarity.load_text(os.path.join(corpus_path, i))\n",
    "                        \n",
    "                        \n",
    "                        temp_text = self.main_cleaning(temp_text)\n",
    "            \n",
    "                        \n",
    "                        \n",
    "                    \n",
    "\n",
    "                        # Update the dictionary and document pool\n",
    "                        self.dictionary.update(set(temp_text))\n",
    "                        self.document_pool[i] = list(set(temp_text))\n",
    "                        new_count+= 1 \n",
    "                    except Exception as e: \n",
    "                        \n",
    "                        raise Exception(f'Failed to load document {i} because of {e}')\n",
    "                        \n",
    "                    \n",
    "                else: \n",
    "                    continue\n",
    "            else: \n",
    "                continue \n",
    "        \n",
    "        # Update the vector pool with new vectors\n",
    "        \n",
    "        \n",
    "        self.update_vectorpool()     \n",
    "        \n",
    "        if new_count == 0: \n",
    "            \n",
    "            return \"no new documents in folder\"\n",
    "        else: \n",
    "            \n",
    "            return f\"where have been {str(new_count)} new documents in the folder\"\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def string_to_list(string1): \n",
    "        \n",
    "        \"\"\"\n",
    "        Static method to convert a cleaned string into a list of words.\n",
    "\n",
    "        Args:\n",
    "            string1 (str): The string to be converted.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of words from the string.\n",
    "            \n",
    "        Raises: \n",
    "            TypeError: If string is not string\n",
    "            ValueError: If string is empty after cleaning \n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(string1, str):\n",
    "            raise TypeError(\"Input must be a string.\")\n",
    "        \n",
    "        \n",
    "        # Convert the cleaned string into a list of words\n",
    "        clean_text = StringSimilarity.cleaning_text(string1)\n",
    "\n",
    "        if not clean_text.strip():\n",
    "            raise ValueError(\"Input string is empty or contains only whitespace after cleaning.\")\n",
    "        \n",
    "        return clean_text.split()\n",
    "\n",
    "\n",
    "    def removing_stopwords(self, list_words): \n",
    "        \n",
    "        \"\"\"\n",
    "        Method to remove stopwords from a list of words.\n",
    "\n",
    "        Args:\n",
    "            list_words (list): The list of words from which stopwords are to be removed.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of words with stopwords removed.\n",
    "            \n",
    "        Raises: \n",
    "            TypError: If Type of Input is not a list of words \n",
    "            ValueError: If list from Input is empty\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        if not isinstance(list_words, list):\n",
    "            raise TypeError(\"Input must be a list of words.\")\n",
    "\n",
    "        if not list_words:\n",
    "            raise ValueError(\"Input list of words is empty.\")\n",
    "        \n",
    "        \n",
    "        # Filter out stopwords from the list of words\n",
    "        text_without_stop = [word for word in list_words if word not in self.stopwords]\n",
    "        \n",
    "        return text_without_stop\n",
    "    \n",
    "    \n",
    "    def main_cleaning(self, text): \n",
    "        \n",
    "        \"\"\"\n",
    "        Method to perform cleaning of the text, converting it into a list of words and removing stopwords. Finally remove words which are shorter than 3\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be cleaned.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of cleaned words from the text.\n",
    "            \n",
    "        Raises: \n",
    "            TypeError: If input is not a string \n",
    "            ValueError: If the input text is empty.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(text, str):\n",
    "            raise TypeError(\"Input must be a string.\")\n",
    "        \n",
    "        \n",
    "        if text.strip() == \"\":\n",
    "            raise ValueError(\"Input text is empty or only contains whitespace.\")\n",
    "        \n",
    "        # Clean text, convert text to a list of words and remove stopwords\n",
    "        text_list = StringSimilarity.string_to_list(text)\n",
    "        text_list = self.removing_stopwords(text_list)\n",
    "        \n",
    "        # Filter out words that are too short (e.g., less than 3 characters)\n",
    "        text_list = [word for word in text_list if len(word) > 2]\n",
    "        \n",
    "        return text_list      \n",
    "    \n",
    "   \n",
    "\n",
    "    def create_vector(self, word_list): \n",
    "        \n",
    "        \"\"\"\n",
    "        Creates a binary vector representation for a given list of words.\n",
    "\n",
    "        Args:\n",
    "            word_list (list): A list of words to be converted into a vector.\n",
    "\n",
    "        Returns:\n",
    "            list: A binary vector where 1 represents the presence of a word from the word list in the dictionary.\n",
    "            \n",
    "        Raises: \n",
    "            TypeError: If the input is not a list.\n",
    "            ValueError: If the input list is empty or the dictionary is not initialized.\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(word_list, list):\n",
    "            raise TypeError(\"Input must be a list of words.\")\n",
    "\n",
    "        if not word_list:\n",
    "            raise ValueError(\"Input word list is empty.\")\n",
    "\n",
    "        if not self.dictionary:\n",
    "            raise ValueError(\"Dictionary is not initialized. Add some documents first.\")\n",
    "        \n",
    "        # Initialize a vector of zeros with the same length as the dictionary\n",
    "        vector = [0] * len(self.dictionary)\n",
    "        \n",
    "\n",
    "        # Set elements to 1 in the vector for words present in the word list\n",
    "        for i, word in enumerate(self.dictionary): \n",
    "            \n",
    "            if word in word_list: \n",
    "                vector[i] = 1\n",
    "            else: \n",
    "                continue \n",
    "            \n",
    "        return vector \n",
    "    \n",
    "    \n",
    "    def update_vectorpool(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Updates the vector representations for all documents in the document pool.\n",
    "        \n",
    "        Raises: \n",
    "            ValueError: If the document pool is empty.\n",
    "        \"\"\" \n",
    "        \n",
    "        \n",
    "        if not self.document_pool:\n",
    "            raise ValueError(\"Document pool is empty. Add some documents before updating the vector pool.\")\n",
    "\n",
    "        # Check if the dictionary is initialized\n",
    "        if not self.dictionary:\n",
    "            raise ValueError(\"Dictionary is not initialized. Add some documents to create the dictionary.\")\n",
    "\n",
    "        try:\n",
    "            # Update vector for each document in the document pool\n",
    "            for i in self.document_pool.keys():\n",
    "                self.vector_pool[i] = self.create_vector(self.document_pool[i])\n",
    "\n",
    "            print(\"All vectors are updated\")\n",
    "            \n",
    "    \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while updating the vector pool: {e}\")\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def rank_vectors(dict1): \n",
    "        \n",
    "        \"\"\"\n",
    "        Ranks vectors based on their values.\n",
    "\n",
    "        Args:\n",
    "            dict1 (dict): A dictionary of vectors to be ranked.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with vectors ranked in descending order of their values.\n",
    "        \n",
    "        Raises:\n",
    "            TypeError: If the input is not a dictionary.\n",
    "            ValueError: If the input dictionary is empty.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if not isinstance(dict1, dict):\n",
    "            raise TypeError(\"Input must be a dictionary.\")\n",
    "\n",
    "        if not dict1:\n",
    "            raise ValueError(\"Input dictionary is empty.\")  \n",
    "\n",
    "        \n",
    "        # Sort the dictionary in descending order based on values\n",
    "        return dict(sorted(dict1.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def dot_product_normal(self, new_doc, new_vector): \n",
    "        \n",
    "        \"\"\"\n",
    "        Calculates the dot product similarity between a new document and all documents in the document pool.\n",
    "\n",
    "        Args:\n",
    "            new_doc (str): The text of the new document.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of dot product similarity scores.\n",
    "        \n",
    "        Raises:\n",
    "            Valueerror: If the type of new_doc is not list.\n",
    "            ValueError: If the new document list is empty.\n",
    "            ValueError: If the document pool is empty.\n",
    "        \"\"\"\n",
    "    \n",
    "\n",
    "        if not isinstance(new_doc, list):\n",
    "            raise TypeError(\"The new document must be a list.\")\n",
    "\n",
    "        if len(new_doc) == 0: \n",
    "            raise ValueError(\"The list of words does not contains any words\")\n",
    "\n",
    "        if not self.document_pool:\n",
    "            raise ValueError(\"Document pool is empty. Add some documents before calculating Euclidean distance.\")\n",
    "        \n",
    "        final_dict = {}\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # Calculate dot product with each document vector\n",
    "        for text in self.document_pool.keys(): \n",
    "\n",
    "            final_dict[text] = np.dot(new_vector, self.vector_pool[text])\n",
    "        \n",
    "        return StringSimilarity.rank_vectors(final_dict)\n",
    "    \n",
    "    \n",
    "\n",
    "    def cosine_Similarity(self, new_doc,new_vector): \n",
    "        \n",
    "        \"\"\"\n",
    "        Calculates the cosine similarity between a new document and all documents in the document pool.\n",
    "\n",
    "        Args:\n",
    "            new_doc (str): The text of the new document.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of cosine similarity scores.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the new document is empty or only contains whitespace.\n",
    "            ValueError: If the document pool is empty.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        if not self.document_pool:\n",
    "            raise ValueError(\"Document pool is empty. Add some documents before calculating cosine similarity.\")\n",
    "        \n",
    "        \n",
    "        cosine_values = {}\n",
    "        \n",
    "        \n",
    "        # cleans new text and create vector\n",
    "        # clean_text = self.main_cleaning(new_doc)\n",
    "        \n",
    "        # new_vector = self.create_vector(clean_text)\n",
    "        \n",
    "        \n",
    "        # Calculate cosine similarity with each document vector\n",
    "        for i in self.document_pool.keys(): \n",
    "            \n",
    "            temp_vector = self.vector_pool[i]\n",
    "            \n",
    "            if norm(new_vector)*norm(temp_vector) != 0: \n",
    "                \n",
    "                cosine = np.dot(new_vector,temp_vector)/(norm(new_vector)*norm(temp_vector))\n",
    "                \n",
    "                cosine_values[i] = cosine\n",
    "                \n",
    "            else: \n",
    "                cosine_values[i] = 'no matches'\n",
    "            \n",
    "        return StringSimilarity.rank_vectors(cosine_values)\n",
    "    \n",
    "    \n",
    "    def Euclidean_distance(self, new_doc, new_vector): \n",
    "        \n",
    "        \"\"\"\n",
    "        Calculates the Euclidean distance between a new document and all documents in the document pool.\n",
    "\n",
    "        Args:\n",
    "            new_doc (str): The text of the new document.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of Euclidean distance scores.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If type of input new_doc is not a list. \n",
    "            ValueError: If the new document list is empty.\n",
    "            ValueError: If the document pool is empty.\n",
    "            \n",
    "        \"\"\"\n",
    "        if not isinstance(new_doc, list):\n",
    "            raise TypeError(\"The new document must be a list.\")\n",
    "\n",
    "        if len(new_doc) == 0: \n",
    "            raise ValueError(\"The list of words does not contains any words\")\n",
    "\n",
    "        if not self.document_pool:\n",
    "            raise ValueError(\"Document pool is empty. Add some documents before calculating Euclidean distance.\")\n",
    "        \n",
    "        euclidean_values = {}\n",
    "        \n",
    "        # cleans new text and create vector\n",
    "        # clean_text = self.main_cleaning(new_doc)\n",
    "        # new_vector = self.create_vector(clean_text)\n",
    "        \n",
    "        \n",
    "        # Calculate Euclidean distance with each document vector\n",
    "        for i in self.document_pool.keys(): \n",
    "            \n",
    "            temp_vector = self.vector_pool[i]\n",
    "            \n",
    "            dist = np.linalg.norm(np.array(temp_vector) - np.array(new_vector))\n",
    "            euclidean_values[i] = dist \n",
    "            \n",
    "        return StringSimilarity.rank_vectors(euclidean_values)\n",
    "    \n",
    "    def Jaccard_similarity(self, new_doc, clean_words): \n",
    "        \n",
    "        \"\"\"\n",
    "        Calculates the Jaccard similarity between a new document and all documents in the document pool.\n",
    "\n",
    "        Args:\n",
    "            new_doc (str): The text of the new document.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary of Jaccard similarity scores.\n",
    "            \n",
    "        Raises:\n",
    "            TypeError: If the new document is not a list.\n",
    "            ValueError: If the new document list \n",
    "            ValueError: If the document pool is empty.\n",
    "        \"\"\"\n",
    "        if not isinstance(new_doc, list):\n",
    "            raise TypeError(\"The new document must be a list.\")\n",
    "\n",
    "        if len(new_doc) == 0: \n",
    "            raise ValueError(\"The list of words does not contains any words\")\n",
    "\n",
    "        if not self.document_pool:\n",
    "            raise ValueError(\"Document pool is empty. Add some documents before calculating Jaccard similarity.\")\n",
    "        jaccard_values = {}\n",
    "        \n",
    "        # cleans new text and create set of words\n",
    "        # clean_text = self.main_cleaning(new_doc)\n",
    "        # set_new_words = set(clean_text)\n",
    "        \n",
    "        # Iterate over each document in the document pool\n",
    "        for name, words in self.document_pool.items(): \n",
    "            \n",
    "            set_old_words = set(words)\n",
    "            \n",
    "            # Calculate the intersection and union\n",
    "            intersection = clean_words.intersection(set_old_words)\n",
    "            union = clean_words.union(set_old_words)\n",
    "\n",
    "            # Calculate Jaccard similarity and add to the dictionary\n",
    "            jaccard_sim = len(intersection) / len(union) if union else 0\n",
    "            jaccard_values[name] = jaccard_sim\n",
    "        \n",
    "        return  StringSimilarity.rank_vectors(jaccard_values)\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_dataframe(dict1, dict2, dict3, dict4): \n",
    "        \n",
    "        \"\"\"\n",
    "        Creates a DataFrame from four dictionaries of similarity scores by each method.\n",
    "\n",
    "        Args:\n",
    "            dict1, dict2, dict3 (dict): Dictionaries of similarity scores seperated by method.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A DataFrame with the similarity scores from the three dictionaries.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        df = pd.DataFrame([dict1,dict2, dict3, dict4])\n",
    "        \n",
    "        df = df.T # Transpose to have keys as rows\n",
    "    \n",
    "        df.columns = [\"dot_product\", \"cosine\", \"Euclidean\", \"jaccard\"]\n",
    "        \n",
    "        return df \n",
    "    \n",
    "    def user_interaction2(self, text_type, method=\"all\", export= \"No\"): \n",
    "        \n",
    "        \"\"\"\n",
    "        Facilitates user interaction for comparing a new text with the document pool.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A DataFrame showing the similarity scores of the new text with each document in the pool.\n",
    "        Raises:\n",
    "            TypeError:  If Input is not a string\n",
    "            ValueError: If User input is empty. \n",
    "            ValueError: If input word not string or file\n",
    "            ValueError: If the Input string is longer than 200 characters. \n",
    "            ValueError: If User input is empty.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if not isinstance(text_type, str):\n",
    "            raise TypeError(\"The text_type must be a string.\")\n",
    "        \n",
    "        if text_type.strip() == \"\":\n",
    "            raise ValueError(\"text_txpe is empty or only contains whitespace. Please enter valid text as argument.\")\n",
    "        \n",
    "        if not text_type in [\"string\", \"file\"]: \n",
    "            raise ValueError(\"argument needs to be either string or file\")\n",
    "        \n",
    "        \n",
    "        if text_type == \"string\": \n",
    "            \n",
    "            \n",
    "        # Prompt the user to enter text\n",
    "            q1 = input('Enter a string under 200 characters')\n",
    "            \n",
    "            if len(q1) > 500: \n",
    "                raise ValueError(\"Your input text was too long!\")\n",
    "            \n",
    "            if q1.strip() == \"\":\n",
    "                raise ValueError(\"Entered text is empty or only contains whitespace. Please enter valid text.\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        if text_type == \"file\": \n",
    "                    # Prompt the user to enter text\n",
    "            q1 = input('Enter the name of the document (needs to be in the same directory as the script)')\n",
    "            \n",
    "            \n",
    "            if q1.strip() == \"\":\n",
    "                raise ValueError(\"Entered text is empty or only contains whitespace. Please enter valid text.\")\n",
    "            \n",
    "            \n",
    "            #check if file is in directory \n",
    "            \n",
    "            objects = os.listdir(os.getcwd())\n",
    "            \n",
    "            if not q1 in objects: \n",
    "                \n",
    "                raise ValueError(f\"The file {q1} is not in the directory of this jupyter notebook.\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            try: \n",
    "                q1 = self.load_text(q1)\n",
    "                \n",
    "    \n",
    "            except Exception as e: \n",
    "                            \n",
    "                raise Exception(f'Failed to load document {q1} because of {e}')\n",
    "            \n",
    "        \n",
    "        # cleans new text and create vector\n",
    "        clean_text = self.main_cleaning(q1)\n",
    "        new_vector = self.create_vector(clean_text)\n",
    "        set_new_words = set(clean_text)\n",
    "        \n",
    "        \n",
    "        try: \n",
    "        # Compute similarity scores\n",
    "            result1 = self.dot_product_normal(clean_text, new_vector)\n",
    "            result2 = self.cosine_Similarity(clean_text,new_vector)\n",
    "            result3 = self.Euclidean_distance(clean_text, new_vector)\n",
    "            result4 = self.Jaccard_similarity(clean_text, set_new_words)\n",
    "            \n",
    "        \n",
    "            \n",
    "            # Create and return a DataFrame with the results  \n",
    "            if method == \"all\":   \n",
    "                final_df = StringSimilarity.create_dataframe(result1, result2, result3, result4)\n",
    "            \n",
    "            elif method == \"dot\": \n",
    "                final_df =  pd.DataFrame(list(result1.items()), columns=['Document', 'Dot Product Similarity'])\n",
    "            \n",
    "            elif method == \"cosine\": \n",
    "                final_df =  pd.DataFrame(list(result2.items()), columns=['Document', 'Cosine Similarity'])\n",
    "            \n",
    "            elif method == \"euclidean\": \n",
    "                final_df =  pd.DataFrame(list(result3.items()), columns=['Document', 'Euclidean Distance'])\n",
    "            \n",
    "            elif method == \"jaccard\": \n",
    "                final_df = pd.DataFrame(list(result4.items()), columns=['Document', 'Jaccard Similarity'])\n",
    "            \n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            raise Exception(f\"An error occurred while calculating similarity scores: {e}\") \n",
    "    \n",
    "        if export == \"No\": \n",
    "            return final_df \n",
    "        \n",
    "        if export == \"Yes\": \n",
    "            try: \n",
    "                final_df.to_excel(\"results.xlsx\")\n",
    "                \n",
    "                print(\"Excel has been created!\")\n",
    "                \n",
    "                return final_df\n",
    "                \n",
    "            except Exception as e: \n",
    "                \n",
    "                raise Exception(f\"An Error occoured by creating Excel {e}\") \n",
    "                \n",
    "    def user_interaction(self, text_type, method=\"all\", export=\"No\"):\n",
    "        \"\"\"\n",
    "        Facilitates user interaction for comparing a new text with the document pool.\n",
    "        \n",
    "        This function allows the user to input a text string or specify a file. It then performs text cleaning,\n",
    "        computes various similarity scores with the documents in the pool, and optionally exports the results to Excel.\n",
    "\n",
    "        Args:\n",
    "            text_type (str): Type of text input, either \"string\" or \"file\".\n",
    "            method (str, optional): The method to use for computing similarity scores. Defaults to \"all\".\n",
    "            export (str, optional): Option to export the results to an Excel file. Defaults to \"No\".\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A DataFrame showing the similarity scores of the new text with each document in the pool.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If text_type is not a string.\n",
    "            ValueError: If export is empty or not 'Yes'/'No'.\n",
    "            ValueError: If text_type is empty or not 'string'/'file'.\n",
    "            ValueError: If the input text is too long (more than 200 characters) or empty.\n",
    "            ValueError: If the specified file is not found in the directory.\n",
    "            Exception: For errors in loading the document or in similarity score calculations.\n",
    "            Exception: For errors encountered while creating the Excel file.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if text_type is a valid string\n",
    "        if not isinstance(text_type, str):\n",
    "            raise TypeError(\"The text_type must be a string.\")\n",
    "        \n",
    "        # Check for empty string\n",
    "        if text_type.strip() == \"\":\n",
    "            raise ValueError(\"text_type is empty or only contains whitespace. Please enter valid text as argument.\")\n",
    "        \n",
    "        # Validate text_type value\n",
    "        if not export in [\"Yes\", \"No\"]: \n",
    "            raise ValueError(\"Argument needs to be either 'Yes' or 'No'.\")\n",
    "        \n",
    "        if not text_type in [\"string\", \"file\"]: \n",
    "            raise ValueError(\"Argument needs to be either 'string' or 'file'.\")\n",
    "\n",
    "        # Handling 'string' input\n",
    "        if text_type == \"string\": \n",
    "            # Prompt the user to enter text\n",
    "            q1 = input('Enter a string under 500 characters')\n",
    "            \n",
    "            # Check for length constraint\n",
    "            if len(q1) < 500: \n",
    "                raise ValueError(\"Your input text was too long!\")\n",
    "            \n",
    "            # Check for empty input\n",
    "            if q1.strip() == \"\":\n",
    "                raise ValueError(\"Entered text is empty or only contains whitespace. Please enter valid text.\")\n",
    "            \n",
    "        # Handling 'file' input\n",
    "        if text_type == \"file\": \n",
    "            # Prompt the user to enter file name\n",
    "            q1 = input('Enter the name of the document (needs to be in the same directory as the script)')\n",
    "            \n",
    "            # Check for empty input\n",
    "            if q1.strip() == \"\":\n",
    "                raise ValueError(\"Entered text is empty or only contains whitespace. Please enter valid text.\")\n",
    "            \n",
    "            # Check if file exists in directory\n",
    "            objects = os.listdir(os.getcwd())\n",
    "            if not q1 in objects: \n",
    "                raise ValueError(f\"The file {q1} is not in the directory of this Jupyter notebook.\")\n",
    "            \n",
    "            # Attempt to load the text from the file\n",
    "            try: \n",
    "                q1 = self.load_text(q1)\n",
    "            except Exception as e: \n",
    "                raise Exception(f'Failed to load document {q1} because of {e}')\n",
    "        \n",
    "        # Clean the text and create vector\n",
    "        clean_text = self.main_cleaning(q1)\n",
    "        new_vector = self.create_vector(clean_text)\n",
    "        set_new_words = set(clean_text)\n",
    "\n",
    "        # Compute and store similarity scores\n",
    "        try: \n",
    "            # Compute similarity scores\n",
    "            result1 = self.dot_product_normal(clean_text, new_vector)\n",
    "            result2 = self.cosine_Similarity(clean_text, new_vector)\n",
    "            result3 = self.Euclidean_distance(clean_text, new_vector)\n",
    "            result4 = self.Jaccard_similarity(clean_text, set_new_words)\n",
    "\n",
    "            # Generate DataFrame based on selected method\n",
    "            if method == \"all\":   \n",
    "                final_df = StringSimilarity.create_dataframe(result1, result2, result3, result4)\n",
    "            elif method == \"dot\": \n",
    "                final_df = pd.DataFrame(list(result1.items()), columns=['Document', 'Dot Product Similarity'])\n",
    "            elif method == \"cosine\": \n",
    "                final_df = pd.DataFrame(list(result2.items()), columns=['Document', 'Cosine Similarity'])\n",
    "            elif method == \"euclidean\": \n",
    "                final_df = pd.DataFrame(list(result3.items()), columns=['Document', 'Euclidean Distance'])\n",
    "            elif method == \"jaccard\": \n",
    "                final_df = pd.DataFrame(list(result4.items()), columns=['Document', 'Jaccard Similarity'])\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while calculating similarity scores: {e}\") \n",
    "\n",
    "        # Handle export option\n",
    "        if export == \"No\": \n",
    "            return final_df \n",
    "        \n",
    "        if export == \"Yes\": \n",
    "            try: \n",
    "                \n",
    "                #export dataframe to results.xlsx\n",
    "                final_df.to_excel(\"results.xlsx\")\n",
    "                print(\"Excel has been created!\")\n",
    "                return final_df\n",
    "            except Exception as e: \n",
    "                raise Exception(f\"An error occurred while creating Excel: {e}\")           \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All vectors are updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['text1.txt', 'text2.txt', 'text3.txt'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class Document_similarity is set up \n",
    "Document_similarity = StringSimilarity()\n",
    "\n",
    "#this line creates the document pool. It will read all files in the Corpus folder and create vectors for each \n",
    "Document_similarity.create_corpus()\n",
    "\n",
    "#displays the document names of the pool\n",
    "Document_similarity.document_pool.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'string', 'stopwords', 'filtert']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All text data will be processed and cleaned with the main_cleaning function \n",
    "\n",
    "text = \"THIS is @n example string!!!stop-words, et 1, , 4 ,5 will be filtert__ out\"\n",
    "\n",
    "Document_similarity.main_cleaning(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has been added to the pool but no new vocabularies were added\n"
     ]
    }
   ],
   "source": [
    "#it is possible to add texts until 500 characters as string to the document pool. \n",
    "#If the string contains vocabularies which were not part of the class dictionary they will be added to the pool and all vectors will be updated \n",
    "\n",
    "test_string = \"this is a test\"\n",
    "Document_similarity.add_documents(\"dummy\", test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For each document a vector will be created with the lenght of the class dictionary \n",
    "Document_similarity.vector_pool[\"dummy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text1.txt', 'text2.txt', 'text3.txt', 'new_doc1'])\n",
      "13396\n",
      "All vectors are updated\n",
      "dict_keys(['text1.txt', 'text2.txt', 'text3.txt', 'new_doc1'])\n",
      "13396\n"
     ]
    }
   ],
   "source": [
    "print(Document_similarity.document_pool.keys())\n",
    "print(len(Document_similarity.vector_pool[\"text1.txt\"]))\n",
    "\n",
    "new_text = \"This text will be added to the document Pool because the script says so \"\n",
    "\n",
    "Document_similarity.add_documents(\"new_doc1\",new_text)\n",
    "\n",
    "print(Document_similarity.document_pool.keys())\n",
    "print(len(Document_similarity.vector_pool[\"text1.txt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dot Product Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text2.txt</td>\n",
       "      <td>3293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text1.txt</td>\n",
       "      <td>2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text3.txt</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document  Dot Product Similarity\n",
       "0  text2.txt                    3293\n",
       "1  text1.txt                    2594\n",
       "2  text3.txt                    1614"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_similarity.user_interaction(\"file\", \"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text2.txt</td>\n",
       "      <td>0.550761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text1.txt</td>\n",
       "      <td>0.519280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text3.txt</td>\n",
       "      <td>0.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_doc1</td>\n",
       "      <td>0.019062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document  Cosine Similarity\n",
       "0  text2.txt           0.550761\n",
       "1  text1.txt           0.519280\n",
       "2  text3.txt           0.402100\n",
       "3   new_doc1           0.019062"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_similarity.user_interaction(\"file\", \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text2.txt</td>\n",
       "      <td>78.752778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text1.txt</td>\n",
       "      <td>70.604532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text3.txt</td>\n",
       "      <td>69.303680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_doc1</td>\n",
       "      <td>64.249514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document  Euclidean Distance\n",
       "0  text2.txt           78.752778\n",
       "1  text1.txt           70.604532\n",
       "2  text3.txt           69.303680\n",
       "3   new_doc1           64.249514"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_similarity.user_interaction(\"file\", \"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Jaccard Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1.txt</td>\n",
       "      <td>0.234624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text2.txt</td>\n",
       "      <td>0.253854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text3.txt</td>\n",
       "      <td>0.163129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_doc1</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document  Jaccard Similarity\n",
       "0  text1.txt            0.234624\n",
       "1  text2.txt            0.253854\n",
       "2  text3.txt            0.163129\n",
       "3   new_doc1            0.000394"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_similarity.user_interaction(\"file\", \"jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel has been created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot_product</th>\n",
       "      <th>cosine</th>\n",
       "      <th>Euclidean</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text2.txt</th>\n",
       "      <td>3293.0</td>\n",
       "      <td>0.550761</td>\n",
       "      <td>78.752778</td>\n",
       "      <td>0.253854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text1.txt</th>\n",
       "      <td>2594.0</td>\n",
       "      <td>0.519280</td>\n",
       "      <td>70.604532</td>\n",
       "      <td>0.234624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text3.txt</th>\n",
       "      <td>1614.0</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>69.303680</td>\n",
       "      <td>0.163129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dot_product    cosine  Euclidean   jaccard\n",
       "text2.txt       3293.0  0.550761  78.752778  0.253854\n",
       "text1.txt       2594.0  0.519280  70.604532  0.234624\n",
       "text3.txt       1614.0  0.402100  69.303680  0.163129"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_similarity.user_interaction(\"file\", export=\"Yes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
